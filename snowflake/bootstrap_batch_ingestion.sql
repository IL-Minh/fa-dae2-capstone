-- Bootstrap Snowflake objects for batch data ingestion DAG
-- Instructions:
-- 1) Replace the placeholders in ALL_CAPS with your values or run in a worksheet after setting:
--      USE ROLE YOUR_ROLE;
--      USE WAREHOUSE YOUR_WAREHOUSE;
-- 2) Execute this script once to create database/schema/tables for the DAG.
-- 3) After this, the DAG will be able to ingest data into these tables.

-- Set your context (optional if already selected in UI)
-- USE ROLE YOUR_ROLE;
-- USE WAREHOUSE YOUR_WAREHOUSE;

-- Replace these names or keep as-is
-- CREATE DATABASE IF NOT EXISTS DB_T0;
USE DATABASE DB_T0;

CREATE SCHEMA IF NOT EXISTS SC_RAW;
USE SCHEMA SC_RAW;

-- CDC table for PostgreSQL ingestion (with additional CDC tracking fields)
CREATE TABLE IF NOT EXISTS TRANSACTIONS_CDC (
    TX_ID STRING PRIMARY KEY,
    USER_ID INTEGER,
    AMOUNT NUMBER(18,2),
    CURRENCY STRING,
    MERCHANT STRING,
    CATEGORY STRING,
    TIMESTAMP TIMESTAMP_NTZ,
    INGESTED_AT TIMESTAMP_NTZ,
    SOURCE_SYSTEM STRING,
    SYNC_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP
);

-- Batch table for CSV ingestion (with source file tracking)
CREATE TABLE IF NOT EXISTS TRANSACTIONS_BATCH (
    TX_ID STRING PRIMARY KEY,
    USER_ID INTEGER,
    AMOUNT NUMBER(18,2),
    CURRENCY STRING,
    MERCHANT STRING,
    CATEGORY STRING,
    TIMESTAMP TIMESTAMP_NTZ,
    SOURCE_FILE STRING,
    INGESTED_AT TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP
);

-- CDC sync log table to track synchronization history
CREATE TABLE IF NOT EXISTS TRANSACTIONS_CDC_SYNC_LOG (
    SYNC_ID AUTOINCREMENT PRIMARY KEY,
    SYNC_TYPE STRING NOT NULL,
    LAST_SYNC_TIMESTAMP TIMESTAMP_NTZ,
    ROWS_SYNCED INTEGER DEFAULT 0,
    SYNC_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP,
    SYNC_STATUS STRING DEFAULT 'SUCCESS'
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS IDX_TRANSACTIONS_CDC_SYNC_TIMESTAMP
ON TRANSACTIONS_CDC(SYNC_TIMESTAMP);

CREATE INDEX IF NOT EXISTS IDX_TRANSACTIONS_CDC_INGESTED_AT
ON TRANSACTIONS_CDC(INGESTED_AT);

CREATE INDEX IF NOT EXISTS IDX_TRANSACTIONS_BATCH_SOURCE_FILE
ON TRANSACTIONS_BATCH(SOURCE_FILE);

CREATE INDEX IF NOT EXISTS IDX_TRANSACTIONS_BATCH_INGESTED_AT
ON TRANSACTIONS_BATCH(INGESTED_AT);

CREATE INDEX IF NOT EXISTS IDX_CDC_SYNC_LOG_SYNC_TYPE
ON TRANSACTIONS_CDC_SYNC_LOG(SYNC_TYPE);

CREATE INDEX IF NOT EXISTS IDX_CDC_SYNC_LOG_TIMESTAMP
ON TRANSACTIONS_CDC_SYNC_LOG(SYNC_TIMESTAMP);

-- Optional: Create a view that combines both sources for analysis
CREATE OR REPLACE VIEW V_TRANSACTIONS_UNIFIED AS
SELECT
    TX_ID,
    USER_ID,
    AMOUNT,
    CURRENCY,
    MERCHANT,
    CATEGORY,
    TIMESTAMP,
    'CDC' as SOURCE_TYPE,
    SOURCE_SYSTEM as SOURCE_DETAIL,
    INGESTED_AT,
    SYNC_TIMESTAMP as PROCESSING_TIMESTAMP
FROM TRANSACTIONS_CDC
UNION ALL
SELECT
    TX_ID,
    USER_ID,
    AMOUNT,
    CURRENCY,
    MERCHANT,
    CATEGORY,
    TIMESTAMP,
    'BATCH' as SOURCE_TYPE,
    SOURCE_FILE as SOURCE_DETAIL,
    INGESTED_AT,
    INGESTED_AT as PROCESSING_TIMESTAMP
FROM TRANSACTIONS_BATCH;

-- Optional: grants (adjust ROLE/USER/SHARE as needed)
-- GRANT USAGE ON DATABASE DB_T0 TO ROLE YOUR_ROLE;
-- GRANT USAGE ON SCHEMA DB_T0.SC_RAW TO ROLE YOUR_ROLE;
-- GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE TRANSACTIONS_CDC TO ROLE YOUR_ROLE;
-- GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE TRANSACTIONS_BATCH TO ROLE YOUR_ROLE;
-- GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE TRANSACTIONS_CDC_SYNC_LOG TO ROLE YOUR_ROLE;
-- GRANT SELECT ON VIEW V_TRANSACTIONS_UNIFIED TO ROLE YOUR_ROLE;

-- Insert initial sync log entry for CDC
INSERT INTO TRANSACTIONS_CDC_SYNC_LOG (SYNC_TYPE, LAST_SYNC_TIMESTAMP, ROWS_SYNCED, SYNC_STATUS)
VALUES ('postgres_cdc', '2021-01-01 00:00:00', 0, 'INITIALIZED')
ON DUPLICATE KEY UPDATE SYNC_STATUS = 'INITIALIZED';

PRINT('âœ… Batch data ingestion tables created successfully!');
PRINT('ðŸ“Š Tables created:');
PRINT('   - TRANSACTIONS_CDC (for PostgreSQL CDC ingestion)');
PRINT('   - TRANSACTIONS_BATCH (for CSV batch ingestion)');
PRINT('   - TRANSACTIONS_CDC_SYNC_LOG (for CDC tracking)');
PRINT('   - V_TRANSACTIONS_UNIFIED (unified view of all data)');
PRINT('');
PRINT('ðŸš€ You can now run the batch_data_ingestion_dag in Airflow!');
